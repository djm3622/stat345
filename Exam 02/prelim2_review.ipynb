{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b43e5cb-27a5-4d19-8d9c-a24413f9c70e",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "What tests have we learned, and when should they be applied (on what kind of data)? Can you also specify when a test needs special ways to deal with ties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8382274f-d61c-44b4-bc30-d7f5afd2639d",
   "metadata": {},
   "source": [
    "## Paired data $\\{(x_i, y_i) \\; | \\; i = 1, \\ldots, n\\}$\n",
    "  - Same location parameter? Is the dist for $D = Y-X$ centered on zero? I.e., test on $d_i = y_i - x_i$. \n",
    "    - Sign test\n",
    "    - (Wilcoxon) Sign rank test\n",
    "  - Correlation: Spreaman $\\rho$, Kendal $\\tau$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bac9b9d-c189-43bf-a024-3a01f71e99a6",
   "metadata": {},
   "source": [
    "## Independent samples $\\{x_i\\; |\\; i=1, \\ldots , n\\}, \\{y_j\\; |\\; j=1, \\ldots , m\\}$\n",
    "  - Equal variances? Conover sqaured ranks test.\n",
    "  - Same location parameter? Count number of times $x_i > y_j$ for all $i$ and $j$. Mann-Whitney test $\\equiv$ (Wilcoxon) rank sum test.\n",
    "  - Compare EDFs: Kolmogorov-Smirnov, Cramer-von Mises, or Anderson-Darling test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af628cab-9298-4686-bbc7-8e00a9d2c97d",
   "metadata": {},
   "source": [
    "## $k$ samples: $\\{x_{i,j}\\;|\\; i=1, \\ldots,k; j=1, \\ldots, n_i\\}$ \n",
    "Generalization: $x_j \\rightarrow x_{1,j}$, $y_j\\rightarrow x_{2, j}$, $n\\rightarrow n_1$, $m\\rightarrow n_2$ etc.\n",
    "\n",
    "- Rank sum test $\\rightarrow$ Kruskal-Wallis test\n",
    "  - Conover-Iman test to check which pairs of samples are responsible.\n",
    "- 2-sample Conover squared ranks $\\rightarrow$ $k$-sample squared ranks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ab9d36-f1af-4cc0-bc81-e2d51a4f05fb",
   "metadata": {},
   "source": [
    "## Complete block design: $\\{x_{i,j}\\;|\\;i=1, \\ldots, b; j=1, \\ldots, k\\}$\n",
    "Compare \"treatments\", labelled by $j$ within each block labelled by $i$. Generalize paired data to $k$ \"samples\".\n",
    "\n",
    "$x_i \\rightarrow x_{i1}$; $y_i \\rightarrow x_{i,2}$ $n\\rightarrow b$\n",
    "\n",
    "- Sign test $\\rightarrow$ Friedman (rank treatments within blocks)\n",
    "- Sign rank test $\\rightarrow$ Quade test (weight ranks by spread within block)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d51642d-5e7c-4d7f-8ec0-a36af20b5776",
   "metadata": {},
   "source": [
    "## ROC curves/ARE/power curves; one sample K-S etc. tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb27a6d0-1cdb-4bc3-9278-5391a64006fa",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "\n",
    "For $p$-values: use Monte Carlo or built-in functions?\n",
    "\n",
    "Answer: Generally okay to use functions providing null distribution (e.g. `stats.ksone()` for Kolmogorov distribution), but don't use function to do the whole test for you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd93acc-67fe-4063-b126-3993878877b9",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "\n",
    "One-sample K-S test for discrete data; what replaces Kolomogorov distribution?\n",
    "\n",
    "Method in Conover section 6.1 (**A Method of Obtain the Exact $p$-Value When $F^*(x)$ is Discrete**) e.g., Example 2, is not recommended.\n",
    "\n",
    "Better to do a Monte Carlo as in lesson 7.2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a020bb-da83-4d4b-b96e-0faee2f57300",
   "metadata": {},
   "source": [
    "# Review\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0d6f4a5-4041-47df-9661-8eaf86b93726",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5691218-bf1a-41ea-ae97-765d0513fa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "plt.rcParams['figure.figsize'] = (8.0,5.0)\n",
    "plt.rcParams['font.size'] = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f180223-17b7-4d0a-93ce-1fffcb6d32c4",
   "metadata": {},
   "source": [
    "## Kruskal-Wallis\n",
    "\n",
    "The null is assumed Chi squared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08350f8a-143a-405a-b603-b578068bbb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kruskal_wallis(x_i_j):\n",
    "    n_i = np.array([len(xi_j) for xi_j in x_i_j])\n",
    "    k = len(n_i)\n",
    "    N = np.sum(n_i)\n",
    "    \n",
    "    x_r = np.concatenate(x_i_j)\n",
    "    R_r = stats.rankdata(x_r)\n",
    "    i_r = np.concatenate([(i,)*n_i[i] for i in range(k)])\n",
    "    R_i_j = [R_r[i_r==i] for i in range(k)]\n",
    "    R_i = np.array([np.sum(Ri_j) for Ri_j in R_i_j])\n",
    "    \n",
    "    Rbar = 0.5*(N+1)\n",
    "    T = (N-1) * np.sum((R_i-n_i*Rbar)**2/n_i) / np.sum((R_r-Rbar)**2)\n",
    "    \n",
    "    p = stats.chi2(df=k-1).sf(T)\n",
    "    \n",
    "    return T, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bc12de9-479b-4340-bd89-e2543867bfba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.153846153846154, 0.12531520484413722)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i_j = [\n",
    "    np.array([ 14.97,   5.80,  25.03,   5.50 ]),\n",
    "    np.array([  5.83,  13.96,  21.96]),\n",
    "    np.array([ 17.89,  23.03,  61.09,   18.62,  55.51])\n",
    "]\n",
    "kruskal_wallis(x_i_j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2921ec74-7229-45c4-b9fa-09b0c5a4e91d",
   "metadata": {},
   "source": [
    "## Conover-Iman\n",
    "\n",
    "The null is `t`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90ce59ac-7d87-46b0-99f6-5604e62db0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conover_iman(newx_i_j):\n",
    "    n_i = np.array([len(xi_j) for xi_j in newx_i_j])\n",
    "    k = len(n_i)\n",
    "    N = np.sum(n_i)\n",
    "    \n",
    "    x_r = np.concatenate(newx_i_j)\n",
    "    R_r = stats.rankdata(x_r)\n",
    "    i_r = np.concatenate([(i,)*n_i[i] for i in range(k)])\n",
    "    R_i_j = [R_r[i_r==i] for i in range(k)]\n",
    "    R_i = np.array([np.sum(Ri_j) for Ri_j in R_i_j])\n",
    "    \n",
    "    Rbar = 0.5*(N+1)\n",
    "    T = (N-1) * np.sum((R_i-n_i*Rbar)**2/n_i) / np.sum((R_r-Rbar)**2)\n",
    "    \n",
    "    newx_r = np.concatenate(newx_i_j)\n",
    "    newR_r = stats.rankdata(newx_r)\n",
    "    \n",
    "    newR_i_j = [newR_r[i_r==i] for i in range(k)]\n",
    "    \n",
    "    newR_i = np.array([np.sum(Ri_j) for Ri_j in newR_i_j])\n",
    "    newSsq = np.sum((newR_r-Rbar)**2)/(N-1)\n",
    "    newRbar_i = newR_i/n_i\n",
    "            \n",
    "    newT = (N-1) * np.sum((newR_i-n_i*Rbar)**2/n_i) / np.sum((newR_r-Rbar)**2); newT\n",
    "    p = stats.chi2(df=k-1).sf(newT)\n",
    "    \n",
    "    newT_ii = (newRbar_i[:,None]-newRbar_i[None,:])/np.sqrt(newSsq*(N-1-T)/(N-k)*(1/n_i[:,None]+1/n_i[None,:]))\n",
    "    ps = 2*stats.t(df=N-k).sf(np.abs(newT_ii))\n",
    "    \n",
    "    return (newT, p), (newT_ii, ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2de1362-cc3b-4931-a114-1367ac83ea68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7.476923076923077, 0.023790676031139445),\n",
       " (array([[ 0.        , -0.87060544, -4.16315718],\n",
       "         [ 0.87060544,  0.        , -2.91360309],\n",
       "         [ 4.16315718,  2.91360309,  0.        ]]),\n",
       "  array([[1.        , 0.40659156, 0.00243626],\n",
       "         [0.40659156, 1.        , 0.01721003],\n",
       "         [0.00243626, 0.01721003, 1.        ]])))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newx_i_j = [\n",
    "    np.array([ 14.97,   5.80,  15.03,   5.50 ]),\n",
    "    np.array([  5.83,  13.96,  21.96 ]),\n",
    "    np.array([ 27.89,  23.03,  61.09,   18.62,  55.51 ])\n",
    "]\n",
    "conover_iman(newx_i_j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa0fd9e-4deb-4bbe-87a2-19b277ce18f3",
   "metadata": {},
   "source": [
    "## Conover Squared-Ranks\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56a4f956-1179-4543-890e-d268b118c222",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conover_squared_ranks_k_sample(x_i_j):\n",
    "    n_i = np.array([len(xi_j) for xi_j in x_i_j])\n",
    "    k = len(n_i)\n",
    "    N = np.sum(n_i)\n",
    "\n",
    "    xbar_i = np.array([np.mean(xi_j) for xi_j in x_i_j])\n",
    "    \n",
    "    U_i_j = [np.abs(xi_j-np.mean(xi_j)) for xi_j in x_i_j]\n",
    "    \n",
    "    U_r = np.concatenate(U_i_j) \n",
    "    RU_r = stats.rankdata(U_r)\n",
    "    i_r = np.concatenate([(i,)*n_i[i] for i in range(k)])\n",
    "    RU_i_j = [RU_r[i_r==i] for i in range(k)]\n",
    "    \n",
    "    S_i = np.array([np.sum(RUi_j**2) for RUi_j in RU_i_j])\n",
    "    Sbar = np.mean(RU_r**2)\n",
    "    \n",
    "    Dsq = N/(N-1)*np.mean((RU_r**2-Sbar)**2)\n",
    "    T = np.sum((S_i-n_i*Sbar)**2/n_i)/Dsq\n",
    "    \n",
    "    p = stats.chi2(df=k-1).sf(T)\n",
    "    \n",
    "    return T, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1404eccf-1e36-4f1b-9df0-32c16c3dca65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.436484543493889, 0.024276602034339175)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i_j = [\n",
    "    np.array([ 14.97,   5.80,  25.03,   5.50 ]),\n",
    "    np.array([  5.83,  13.96,  21.96]),\n",
    "    np.array([ 17.89,  23.03,  61.09,   18.62,  55.51])\n",
    "]\n",
    "conover_squared_ranks_k_sample(x_i_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fed74796-d2cd-407c-8b21-89c7d64e16e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.3133164235890935, 0.1282701146119386)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i = np.array([8.56, 5.03, 48.1, 1.31, 4.82]); y_j = np.array([15.0, 12.3, 28.0, 13.9])\n",
    "x_i_j = [x_i, y_j]\n",
    "conover_squared_ranks_k_sample(x_i_j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c275738-9746-415b-b2e2-73fce0d853a3",
   "metadata": {},
   "source": [
    "## Pearson’s $r$\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcb31e2b-8e64-4d02-a638-197e58fc0e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pearsons_r(x_i, y_i):\n",
    "    xbar = np.mean(x_i)\n",
    "    ybar = np.mean(y_i)\n",
    "    \n",
    "    return np.sum((x_i-xbar)*(y_i-ybar))/np.sqrt(np.sum((x_i-xbar)**2)*np.sum((y_i-ybar)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d26c5875-399b-44f9-854d-3a578206053e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5901002196595794"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i = np.array([9.64, 5.91, 3.22, 2.04, 5.49, 9.24, 6.38, 7.79, 0.48, 8.86])\n",
    "y_i = np.array([5.53, 3.48, 3.16, 2.98, 7.11, 7.75, 3.37, 8.24, 3.00, 3.75])\n",
    "\n",
    "get_pearsons_r(x_i, y_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994ca101-2c37-4288-bca9-4448c09e8fef",
   "metadata": {},
   "source": [
    "## Spearman’s $\\rho$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "291062e0-c803-455c-ba30-d34143a47649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spearmans_rho(x_i, y_i):\n",
    "    Rx_i = stats.rankdata(x_i)\n",
    "    Ry_i = stats.rankdata(y_i)\n",
    "    \n",
    "    Rbar = np.mean(Rx_i)\n",
    "    \n",
    "    rho = np.sum((Rx_i-Rbar)*(Ry_i-Rbar) / np.sqrt(np.sum((Rx_i-Rbar)**2)*np.sum((Ry_i-Rbar)**2)))\n",
    "    \n",
    "    return rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e37d0a2c-5969-44e7-9f74-837c6b9788b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7333333333333334"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_spearmans_rho(x_i, y_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8f2184-eccd-429d-92a6-61a105bc5b99",
   "metadata": {},
   "source": [
    "## Kendall’s $\\tau$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "693eb0d2-f8bc-42e7-b02c-1295868d930d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kendall_tau(x_i, y_i):\n",
    "    def is_concordant(pt1,pt2):\n",
    "        return ((pt1[0]>pt2[0])&(pt1[1]>pt2[1])|(pt1[0]<pt2[0])&(pt1[1]<pt2[1]))\n",
    "    def is_discordant(pt1,pt2):\n",
    "        return ((pt1[0]>pt2[0])&(pt1[1]<pt2[1])|(pt1[0]<pt2[0])&(pt1[1]>pt2[1]))\n",
    "    \n",
    "    assert len(x_i) == len(y_i)\n",
    "    n = len(x_i)\n",
    "    \n",
    "    Nc = np.sum([is_concordant((x_i[i],y_i[i]),(x_i[j],y_i[j])) for (i,j) in itertools.combinations(range(n),2)])\n",
    "    Nd = np.sum([is_discordant((x_i[i],y_i[i]),(x_i[j],y_i[j])) for (i,j) in itertools.combinations(range(n),2)])\n",
    "    \n",
    "    tau = (Nc-Nd)/(Nc+Nd); tau\n",
    "    \n",
    "    return tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26598a9e-24ae-4be5-9028-3d085f1e34ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5555555555555556"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_kendall_tau(x_i, y_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7209a8-f6c4-431f-bc40-f9ae40cfbe89",
   "metadata": {},
   "source": [
    "## Friedman \n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3025c74b-033c-4f2b-bbf6-d61f59f61036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_friedman(X_ij):\n",
    "    b, k = np.shape(X_ij)\n",
    "    \n",
    "    R_ij = stats.rankdata(X_ij,axis=-1)\n",
    "    R_j = np.sum(R_ij,axis=0)\n",
    "    \n",
    "    T1 = (12/(b*k*(k+1)))*np.sum((R_j-0.5*b*(k+1))**2)\n",
    "    p = stats.chi2(df=k-1).sf(T1)\n",
    "    \n",
    "    return T1, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1a2902f-8ee3-4bd1-b606-77d8a0291146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.0, 0.36787944117144245)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ij = np.array(\n",
    "    [[  2.  ,  19.86,   9.17],\n",
    "     [  1.05,   3.1 ,   3.34],\n",
    "     [  0.14,  25.4 ,  26.59],\n",
    "     [ 14.6 ,   3.93,  10.95]]\n",
    ")\n",
    "get_friedman(X_ij)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cc63e6-1c43-464c-9858-d2024cfb1416",
   "metadata": {},
   "source": [
    "## Quade \n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c8da30e-1697-4ce3-b3cc-8847d3b60b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quade(X_ij):\n",
    "    b, k = np.shape(X_ij)\n",
    "    \n",
    "    M_i = np.max(X_ij,axis=-1)-np.min(X_ij,axis=-1)\n",
    "    Q_i = stats.rankdata(M_i)\n",
    "    \n",
    "    R_ij = stats.rankdata(X_ij,axis=-1)\n",
    "    R_j = np.sum(R_ij,axis=0)\n",
    "    \n",
    "    S_ij = Q_i[:,None]*(R_ij-0.5*(k+1))\n",
    "    \n",
    "    S_j = np.sum(S_ij,axis=0)\n",
    "    \n",
    "    B = np.sum(S_j**2)/b\n",
    "    A2 = np.sum(S_ij**2)\n",
    "    T3 = (b-1)*B/(A2-B)\n",
    "    \n",
    "    p = stats.f(k-1,(b-1)*(k-1)).sf(T3)\n",
    "    \n",
    "    return T3, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6f6db7d-67ae-4079-914e-71d10ef2459b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0449438202247192, 0.40796817129629637)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quade(X_ij)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed5f62a-3f3f-4a10-ba53-87adeb6cad8e",
   "metadata": {},
   "source": [
    "## Continous Kolmagorov\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6135c50e-103e-4090-8132-5cf361ce0208",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cont_kolmagorov(x_i, Fstar_i):\n",
    "    n = len(x_i)\n",
    "    \n",
    "    Fhatp_i = np.arange(n)/n\n",
    "    Fhatm_i = (1+np.arange(n))/n\n",
    "    \n",
    "    Tp = max(Fstar_i-Fhatp_i)\n",
    "    Tm = max(Fhatm_i-Fstar_i)\n",
    "    T = max(Tp, Tm)\n",
    "    \n",
    "    p = stats.ksone(n).sf(T)\n",
    "    \n",
    "    return T, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bbaa9e83-b76d-48de-82d2-99acaf91823d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.43891370030713844, 0.014275830316232892)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i = np.array([-1.82, 0.72, 1.67, 1.09, 0.64, 0.81, 1.74, -0.80, -0.13, 1.12])\n",
    "Fstar_i = stats.norm.cdf(np.sort(x_i))\n",
    "cont_kolmagorov(x_i, Fstar_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bf25ef-5b26-45c8-8f42-772e12326348",
   "metadata": {},
   "source": [
    "## Discrete Kolmagorov\n",
    "\n",
    "Did not implement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3baee74-fd4d-4aef-9172-108e47d355ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dis_kolmagorov():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8498adf5-5b1e-4a9e-ba43-ed0c6da59202",
   "metadata": {},
   "source": [
    "## Lilliefors\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a2490f1d-c3b0-45ca-af37-95059b58f790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lilliefors(x_i, stardist, sourcedist):\n",
    "    x_i.sort()\n",
    "    n = len(x_i)\n",
    "    \n",
    "    Fstar_i = stardist.cdf(x_i)\n",
    "    Fhatp_i = np.arange(n)/n \n",
    "    Fhatm_i = (1+np.arange(n))/n\n",
    "    \n",
    "    Tp = max(Fstar_i-Fhatp_i) \n",
    "    Tm = max(Fhatm_i-Fstar_i)\n",
    "    T = max(Tp,Tm)\n",
    "    \n",
    "    np.random.seed(20230327)\n",
    "    Nmonte = 10**5\n",
    "    x_Ii = sourcedist.rvs(size=(Nmonte,n))\n",
    "    x_Ii.sort(axis=-1)\n",
    "    \n",
    "    xbar_I = np.mean(x_Ii,axis=-1)\n",
    "    s_I = np.std(x_Ii,axis=-1,ddof=1)\n",
    "    \n",
    "    Fstar_Ii = sourcedist.cdf((x_Ii-xbar_I[:,None])/s_I[:,None])\n",
    "    \n",
    "    Tp_I = np.max(Fstar_Ii-Fhatp_i[None,:],axis=-1)\n",
    "    Tm_I = np.max(Fhatm_i[None,:]-Fstar_Ii,axis=-1)\n",
    "    T_I = np.maximum(Tp_I,Tm_I)\n",
    "    \n",
    "    p = np.mean(T_I>=T)\n",
    "    \n",
    "    return T, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07849b4b-36ce-4f02-92d9-fc9919ca1681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.11334112306628319, 0.00307)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i = np.array([-0.6106, -0.2310, -1.0372, -2.1245, 0.7290, 0.0136, -1.4146, -1.0677, -2.6589,  0.0709, 0.7706, 3.7948, -1.4862, -0.0701, -1.3513, -0.8655, -0.2769, -0.5387, 0.2276, -0.0120, -3.8585, 0.0835, -1.7957, 1.0703, -0.6074, -0.8175, -0.9521, 0.6801, 2.5205, 0.1078, -1.2938, -0.6855, -2.1204, -0.3684, -0.4298, -1.2256, 1.3653, -2.2061, -1.6217, -2.3376,    -1.1890, -1.9026, 0.3447, 2.7895, -0.5585, 1.6562, -3.4243, -0.9751,0.6078, -0.6654, -1.5980, 0.0568, 1.0073, -4.0373, -1.1408, 1.3027,-0.0781, 2.2652, -2.5808, 0.5551, 1.7056, 0.6155, 0.3708, -0.7449,0.7294, -1.6789, 0.2668, 1.3637, -1.1435, -4.5174, 0.1851, -0.4093,-0.1503, 0.4865, -0.7953, -1.6489, -0.5183, 0.6161, -0.5087, -1.3621,3.3161, 0.3884, -1.0508, 0.5203, 0.2696, -1.4678, -1.4626, 0.9397,-7.0490, -0.6900, 3.3881, -0.6778, -1.4596, 0.1268, 8.7628, -1.0302,1.3928, -0.4755, -0.1050, -1.2061 ])\n",
    "stardist = stats.norm(loc=np.mean(x_i),scale=np.std(x_i, ddof=1))\n",
    "sourcedist = stats.norm\n",
    "\n",
    "lilliefors(x_i, stardist, sourcedist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d41feea-3f7a-4ef1-b99b-475c9242c28e",
   "metadata": {},
   "source": [
    "## Cramér-von Mises\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a0b5ec1-8865-49b0-b2cb-dae0a7b674fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cramer_von_mises(x_i, stardist, sourcedist):\n",
    "    x_i.sort()\n",
    "    n = len(x_i)\n",
    "    \n",
    "    Fstar_i = stardist.cdf(x_i)\n",
    "    Fhatp_i = np.arange(n)/n \n",
    "    Fhatm_i = (1+np.arange(n))/n\n",
    "    \n",
    "    i_i = np.arange(1,n+1) \n",
    "    TCvM = 1./(12.*n) + np.sum(((2*i_i-1)/(2.*n)-Fstar_i)**2)\n",
    "    \n",
    "    np.random.seed(20230327)\n",
    "    Nmonte = 10**5\n",
    "    x_Ii = sourcedist.rvs(size=(Nmonte,n))\n",
    "    x_Ii.sort(axis=-1)\n",
    "    \n",
    "    xbar_I = np.mean(x_Ii,axis=-1)\n",
    "    s_I = np.std(x_Ii,axis=-1,ddof=1)\n",
    "    \n",
    "    Fstar_Ii = sourcedist.cdf((x_Ii-xbar_I[:,None])/s_I[:,None])\n",
    "    \n",
    "    TCvM_I = 1./(12.*n) + np.sum(((2*i_i[None,:]-1)/(2.*n)-Fstar_Ii)**2,axis=-1)\n",
    "    \n",
    "    p = np.mean(TCvM_I>=TCvM)\n",
    "    \n",
    "    return TCvM, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "981f0e31-eced-4f3d-91a5-8f0dbd9b19cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3373679828059199, 6e-05)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cramer_von_mises(x_i, stardist, sourcedist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e981c610-c457-45fc-bbbb-8bd42f008561",
   "metadata": {},
   "source": [
    "## Anderson-Darling\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b85265a3-3643-4b59-a5de-0c7f6e5123c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anderson_darling(x_i, stardist, sourcedist):\n",
    "    x_i.sort()\n",
    "    n = len(x_i)\n",
    "    \n",
    "    Fstar_i = stardist.cdf(x_i)\n",
    "    Fhatp_i = np.arange(n)/n \n",
    "    Fhatm_i = (1+np.arange(n))/n\n",
    "    \n",
    "    i_i = np.arange(1,n+1) \n",
    "    A2 = -n-np.sum(((2*i_i-1.)/n)*(np.log(Fstar_i*(1-Fstar_i[::-1]))))\n",
    "    \n",
    "    np.random.seed(20230327)\n",
    "    Nmonte = 10**5\n",
    "    x_Ii = sourcedist.rvs(size=(Nmonte,n))\n",
    "    x_Ii.sort(axis=-1)\n",
    "    \n",
    "    xbar_I = np.mean(x_Ii,axis=-1)\n",
    "    s_I = np.std(x_Ii,axis=-1,ddof=1)\n",
    "    \n",
    "    Fstar_Ii = sourcedist.cdf((x_Ii-xbar_I[:,None])/s_I[:,None])\n",
    "    \n",
    "    A2_I = -n-np.sum(((2*i_i[None,:]-1.)/n)*(np.log(Fstar_Ii*(1-Fstar_Ii[:,::-1]))),axis=-1)\n",
    "    \n",
    "    p = np.mean(A2_I>=A2), np.max(A2_I)\n",
    "    \n",
    "    return A2, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3157429d-ab34-47e4-a074-55018ef1ac20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.0771241595155914, (0.0, 2.0148593650561395))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anderson_darling(x_i, stardist, sourcedist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29863b1b-9bbe-42b4-9788-77c155b9d6f0",
   "metadata": {},
   "source": [
    "## Two-Sample Kolmogorov-Smirnov\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6cfc5c76-56a1-4207-96a3-ee590a8aa09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_sample_kolmogorov(x_i, y_j):\n",
    "    n = len(x_i)\n",
    "    m = len(y_j)\n",
    "    N=n+m\n",
    "    x_i.sort()\n",
    "    y_j.sort()\n",
    "    \n",
    "    Fxhat_i = (1.+np.arange(n))/n\n",
    "    Fyhat_j = (1.+np.arange(m))/m\n",
    "    X_k = np.concatenate((x_i,y_j))\n",
    "    X_k.sort()\n",
    "    \n",
    "    Fxhat_k = np.mean(x_i[None,:] <= X_k[:,None], axis=-1)\n",
    "    Fyhat_k = np.mean(y_j[None,:] <= X_k[:,None], axis=-1)\n",
    "\n",
    "    Tp = max(Fxhat_k-Fyhat_k)\n",
    "    Tm = max(Fyhat_k-Fxhat_k)\n",
    "    T = max(Tp,Tm)\n",
    "    \n",
    "    Rxy_k = stats.rankdata(np.concatenate((x_i,y_j))) \n",
    "    Rx_i=Rxy_k[:n] \n",
    "    Ry_j=Rxy_k[n:]\n",
    "    RX_k = np.sort(Rxy_k)\n",
    "    \n",
    "    xranks_Ii = np.array([xranks_i for xranks_i in itertools.combinations(RX_k,n)])\n",
    "    yranks_Ij = np.array([np.setdiff1d(RX_k,xranks_i) for xranks_i in xranks_Ii])\n",
    "    \n",
    "    Fxhat_Ik = np.mean(xranks_Ii[:,None,:]<=RX_k[None,:,None],axis=-1)\n",
    "    Fyhat_Ik = np.array([np.mean(yranks_j[None,:]<=RX_k[:,None], axis=-1) for yranks_j in yranks_Ij])\n",
    "    \n",
    "    Tp_I = np.max(Fxhat_Ik-Fyhat_Ik,axis=-1)\n",
    "    Tm_I = np.max(Fyhat_Ik-Fxhat_Ik,axis=-1)\n",
    "    T_I = np.max(np.abs(Fxhat_Ik-Fyhat_Ik),axis=-1)\n",
    "    \n",
    "    Tp_I = np.round(Tp_I,decimals=8)\n",
    "    Tm_I = np.round(Tm_I,decimals=8)\n",
    "    T_I = np.maximum(Tp_I,Tm_I); np.unique(T_I)\n",
    "    \n",
    "    p = np.mean(T_I>=T)\n",
    "    \n",
    "    return T, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "51078a9a-1533-40dd-b3b9-9c18197a948b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 0.9)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i = np.array([3.14,0.1,2.72]) \n",
    "y_j = np.array([2,4])\n",
    "two_sample_kolmogorov(x_i, y_j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e33fde0-6a68-4368-afdf-3ea55fab613a",
   "metadata": {},
   "source": [
    "## Two-Sample Cramér-von Mises \n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d5877828-493e-4f69-a745-50589b528ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_sample_cramer_von(x_i, y_j):\n",
    "    n = len(x_i)\n",
    "    m = len(y_j)\n",
    "    N=n+m\n",
    "    x_i.sort()\n",
    "    y_j.sort()\n",
    "    \n",
    "    Fxhat_i = (1.+np.arange(n))/n\n",
    "    Fyhat_j = (1.+np.arange(m))/m\n",
    "    X_k = np.concatenate((x_i,y_j))\n",
    "    X_k.sort()\n",
    "    \n",
    "    Fxhat_k = np.mean(x_i[None,:] <= X_k[:,None], axis=-1)\n",
    "    Fyhat_k = np.mean(y_j[None,:] <= X_k[:,None], axis=-1)\n",
    "\n",
    "    TCvM = n*m/N**2 * np.sum((Fxhat_k-Fyhat_k)**2)\n",
    "    TCvM = np.round(TCvM,8)\n",
    "    \n",
    "    Rxy_k = stats.rankdata(np.concatenate((x_i,y_j))) \n",
    "    Rx_i=Rxy_k[:n] \n",
    "    Ry_j=Rxy_k[n:]\n",
    "    RX_k = np.sort(Rxy_k)\n",
    "    \n",
    "    xranks_Ii = np.array([xranks_i for xranks_i in itertools.combinations(RX_k,n)])\n",
    "    yranks_Ij = np.array([np.setdiff1d(RX_k,xranks_i) for xranks_i in xranks_Ii])\n",
    "    \n",
    "    Fxhat_Ik = np.mean(xranks_Ii[:,None,:]<=RX_k[None,:,None],axis=-1)\n",
    "    Fyhat_Ik = np.array([np.mean(yranks_j[None,:]<=RX_k[:,None], axis=-1) for yranks_j in yranks_Ij])\n",
    "    \n",
    "    TCvM_I = n*m/N**2 * np.sum((Fxhat_Ik-Fyhat_Ik)**2,axis=-1)\n",
    "    TCvM_I = np.round(TCvM_I,8)\n",
    "    \n",
    "    p = np.mean(TCvM_I >= TCvM)\n",
    "    \n",
    "    return TCvM, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f05ef797-3ea0-4d74-bccb-f462ecd8a93c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1, 0.9)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_sample_cramer_von(x_i, y_j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b5382c-d5e4-4829-92c6-beadb6260b39",
   "metadata": {},
   "source": [
    "## Two-Sample Anderson Darling \n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b3f80c42-3b7b-4c0f-95c5-08fe3466ed2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_sample_anderson(x_i, y_j):\n",
    "    n = len(x_i)\n",
    "    m = len(y_j)\n",
    "    N=n+m\n",
    "    x_i.sort()\n",
    "    y_j.sort()\n",
    "    k_k = 1 + np.arange(N)\n",
    "\n",
    "    Fxhat_i = (1.+np.arange(n))/n\n",
    "    Fyhat_j = (1.+np.arange(m))/m\n",
    "    X_k = np.concatenate((x_i,y_j))\n",
    "    X_k.sort()\n",
    "    \n",
    "    Fxhat_k = np.mean(x_i[None,:] <= X_k[:,None], axis=-1)\n",
    "    Fyhat_k = np.mean(y_j[None,:] <= X_k[:,None], axis=-1)\n",
    "    \n",
    "    A2 = n*m*np.sum( (Fxhat_k[:-1]-Fyhat_k[:-1])**2 / (k_k[:-1]*(N-k_k[:-1])) )\n",
    "    A2 = np.round(A2,8)\n",
    "    \n",
    "    Rxy_k = stats.rankdata(np.concatenate((x_i,y_j))) \n",
    "    Rx_i=Rxy_k[:n] \n",
    "    Ry_j=Rxy_k[n:]\n",
    "    RX_k = np.sort(Rxy_k)\n",
    "    \n",
    "    xranks_Ii = np.array([xranks_i for xranks_i in itertools.combinations(RX_k,n)])\n",
    "    yranks_Ij = np.array([np.setdiff1d(RX_k,xranks_i) for xranks_i in xranks_Ii])\n",
    "    \n",
    "    Fxhat_Ik = np.mean(xranks_Ii[:,None,:]<=RX_k[None,:,None],axis=-1)\n",
    "    Fyhat_Ik = np.array([np.mean(yranks_j[None,:]<=RX_k[:,None], axis=-1) for yranks_j in yranks_Ij])\n",
    "        \n",
    "    A2_I = n*m*np.sum( (Fxhat_Ik[:,:-1]-Fyhat_Ik[:,:-1])**2 / (k_k[None,:-1]*(N-k_k[None,:-1])), axis=-1 )\n",
    "    A2_I = np.round(A2_I,8)\n",
    "    \n",
    "    p = np.mean(A2_I>=A2)\n",
    "    \n",
    "    return A2, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fe4754c2-a46e-474f-b989-17ce372da149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.59722222, 0.9)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_sample_anderson(x_i, y_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbca48d-7bd0-473d-87ca-5de9d8986135",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
