{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b43e5cb-27a5-4d19-8d9c-a24413f9c70e",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "What tests have we learned, and when should they be applied (on what kind of data)? Can you also specify when a test needs special ways to deal with ties."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8382274f-d61c-44b4-bc30-d7f5afd2639d",
   "metadata": {},
   "source": [
    "## Paired data $\\{(x_i, y_i) \\; | \\; i = 1, \\ldots, n\\}$\n",
    "  - Same location parameter? Is the dist for $D = Y-X$ centered on zero? I.e., test on $d_i = y_i - x_i$. \n",
    "    - Sign test\n",
    "    - (Wilcoxon) Sign rank test\n",
    "  - Correlation: Spreaman $\\rho$, Kendal $\\tau$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bac9b9d-c189-43bf-a024-3a01f71e99a6",
   "metadata": {},
   "source": [
    "## Independent samples $\\{x_i\\; |\\; i=1, \\ldots , n\\}, \\{y_j\\; |\\; j=1, \\ldots , m\\}$\n",
    "  - Equal variances? Conover sqaured ranks test.\n",
    "  - Same location parameter? Count number of times $x_i > y_j$ for all $i$ and $j$. Mann-Whitney test $\\equiv$ (Wilcoxon) rank sum test.\n",
    "  - Compare EDFs: Kolmogorov-Smirnov, Cramer-von Mises, or Anderson-Darling test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af628cab-9298-4686-bbc7-8e00a9d2c97d",
   "metadata": {},
   "source": [
    "## $k$ samples: $\\{x_{i,j}\\;|\\; i=1, \\ldots,k; j=1, \\ldots, n_i\\}$ \n",
    "Generalization: $x_j \\rightarrow x_{1,j}$, $y_j\\rightarrow x_{2, j}$, $n\\rightarrow n_1$, $m\\rightarrow n_2$ etc.\n",
    "\n",
    "- Rank sum test $\\rightarrow$ Kruskal-Wallis test\n",
    "  - Conover-Iman test to check which pairs of samples are responsible.\n",
    "- 2-sample Conover squared ranks $\\rightarrow$ $k$-sample squared ranks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ab9d36-f1af-4cc0-bc81-e2d51a4f05fb",
   "metadata": {},
   "source": [
    "## Complete block design: $\\{x_{i,j}\\;|\\;i=1, \\ldots, b; j=1, \\ldots, k\\}$\n",
    "Compare \"treatments\", labelled by $j$ within each block labelled by $i$. Generalize paired data to $k$ \"samples\".\n",
    "\n",
    "$x_i \\rightarrow x_{i1}$; $y_i \\rightarrow x_{i,2}$ $n\\rightarrow b$\n",
    "\n",
    "- Sign test $\\rightarrow$ Friedman (rank treatments within blocks)\n",
    "- Sign rank test $\\rightarrow$ Quade test (weight ranks by spread within block)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d51642d-5e7c-4d7f-8ec0-a36af20b5776",
   "metadata": {},
   "source": [
    "## ROC curves/ARE/power curves; one sample K-S etc. tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb27a6d0-1cdb-4bc3-9278-5391a64006fa",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "\n",
    "For $p$-values: use Monte Carlo or built-in functions?\n",
    "\n",
    "Answer: Generally okay to use functions providing null distribution (e.g. `stats.ksone()` for Kolmogorov distribution), but don't use function to do the whole test for you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd93acc-67fe-4063-b126-3993878877b9",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "\n",
    "One-sample K-S test for discrete data; what replaces Kolomogorov distribution?\n",
    "\n",
    "Method in Conover section 6.1 (**A Method of Obtain the Exact $p$-Value When $F^*(x)$ is Discrete**) e.g., Example 2, is not recommended.\n",
    "\n",
    "Better to do a Monte Carlo as in lesson 7.2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a020bb-da83-4d4b-b96e-0faee2f57300",
   "metadata": {},
   "source": [
    "# Review\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0d6f4a5-4041-47df-9661-8eaf86b93726",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b5691218-bf1a-41ea-ae97-765d0513fa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "plt.rcParams['figure.figsize'] = (8.0,5.0)\n",
    "plt.rcParams['font.size'] = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f180223-17b7-4d0a-93ce-1fffcb6d32c4",
   "metadata": {},
   "source": [
    "## Kruskal-Wallis\n",
    "\n",
    "The null is assumed Chi squared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "08350f8a-143a-405a-b603-b578068bbb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kruskal_wallis(x_i_j):\n",
    "    n_i = np.array([len(xi_j) for xi_j in x_i_j])\n",
    "    k = len(n_i)\n",
    "    N = np.sum(n_i)\n",
    "    \n",
    "    x_r = np.concatenate(x_i_j)\n",
    "    R_r = stats.rankdata(x_r)\n",
    "    i_r = np.concatenate([(i,)*n_i[i] for i in range(k)])\n",
    "    R_i_j = [R_r[i_r==i] for i in range(k)]\n",
    "    R_i = np.array([np.sum(Ri_j) for Ri_j in R_i_j])\n",
    "    \n",
    "    Rbar = 0.5*(N+1)\n",
    "    T = (N-1) * np.sum((R_i-n_i*Rbar)**2/n_i) / np.sum((R_r-Rbar)**2)\n",
    "    \n",
    "    p = stats.chi2(df=k-1).sf(T)\n",
    "    \n",
    "    return T, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4bc12de9-479b-4340-bd89-e2543867bfba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.153846153846154, 0.12531520484413722)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i_j = [\n",
    "    np.array([ 14.97,   5.80,  25.03,   5.50 ]),\n",
    "    np.array([  5.83,  13.96,  21.96]),\n",
    "    np.array([ 17.89,  23.03,  61.09,   18.62,  55.51])\n",
    "]\n",
    "kruskal_wallis(x_i_j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2921ec74-7229-45c4-b9fa-09b0c5a4e91d",
   "metadata": {},
   "source": [
    "## Conover-Iman\n",
    "\n",
    "The null is `t`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "90ce59ac-7d87-46b0-99f6-5604e62db0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conover_iman(newx_i_j):\n",
    "    n_i = np.array([len(xi_j) for xi_j in newx_i_j])\n",
    "    k = len(n_i)\n",
    "    N = np.sum(n_i)\n",
    "    \n",
    "    x_r = np.concatenate(newx_i_j)\n",
    "    R_r = stats.rankdata(x_r)\n",
    "    i_r = np.concatenate([(i,)*n_i[i] for i in range(k)])\n",
    "    R_i_j = [R_r[i_r==i] for i in range(k)]\n",
    "    R_i = np.array([np.sum(Ri_j) for Ri_j in R_i_j])\n",
    "    \n",
    "    Rbar = 0.5*(N+1)\n",
    "    T = (N-1) * np.sum((R_i-n_i*Rbar)**2/n_i) / np.sum((R_r-Rbar)**2)\n",
    "    \n",
    "    newx_r = np.concatenate(newx_i_j)\n",
    "    newR_r = stats.rankdata(newx_r)\n",
    "    \n",
    "    newR_i_j = [newR_r[i_r==i] for i in range(k)]\n",
    "    \n",
    "    newR_i = np.array([np.sum(Ri_j) for Ri_j in newR_i_j])\n",
    "    newSsq = np.sum((newR_r-Rbar)**2)/(N-1)\n",
    "    newRbar_i = newR_i/n_i\n",
    "            \n",
    "    newT = (N-1) * np.sum((newR_i-n_i*Rbar)**2/n_i) / np.sum((newR_r-Rbar)**2); newT\n",
    "    p = stats.chi2(df=k-1).sf(newT)\n",
    "    \n",
    "    newT_ii = (newRbar_i[:,None]-newRbar_i[None,:])/np.sqrt(newSsq*(N-1-T)/(N-k)*(1/n_i[:,None]+1/n_i[None,:]))\n",
    "    ps = 2*stats.t(df=N-k).sf(np.abs(newT_ii))\n",
    "    \n",
    "    return (newT, p), (newT_ii, ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e2de1362-cc3b-4931-a114-1367ac83ea68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7.476923076923077, 0.023790676031139445),\n",
       " (array([[ 0.        , -0.87060544, -4.16315718],\n",
       "         [ 0.87060544,  0.        , -2.91360309],\n",
       "         [ 4.16315718,  2.91360309,  0.        ]]),\n",
       "  array([[1.        , 0.40659156, 0.00243626],\n",
       "         [0.40659156, 1.        , 0.01721003],\n",
       "         [0.00243626, 0.01721003, 1.        ]])))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newx_i_j = [\n",
    "    np.array([ 14.97,   5.80,  15.03,   5.50 ]),\n",
    "    np.array([  5.83,  13.96,  21.96 ]),\n",
    "    np.array([ 27.89,  23.03,  61.09,   18.62,  55.51 ])\n",
    "]\n",
    "conover_iman(newx_i_j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa0fd9e-4deb-4bbe-87a2-19b277ce18f3",
   "metadata": {},
   "source": [
    "## Conover Squared-Ranks\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "56a4f956-1179-4543-890e-d268b118c222",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conover_squared_ranks_k_sample(x_i_j):\n",
    "    n_i = np.array([len(xi_j) for xi_j in x_i_j])\n",
    "    k = len(n_i)\n",
    "    N = np.sum(n_i)\n",
    "\n",
    "    xbar_i = np.array([np.mean(xi_j) for xi_j in x_i_j])\n",
    "    \n",
    "    U_i_j = [np.abs(xi_j-np.mean(xi_j)) for xi_j in x_i_j]\n",
    "    \n",
    "    U_r = np.concatenate(U_i_j) \n",
    "    RU_r = stats.rankdata(U_r)\n",
    "    i_r = np.concatenate([(i,)*n_i[i] for i in range(k)])\n",
    "    RU_i_j = [RU_r[i_r==i] for i in range(k)]\n",
    "    \n",
    "    S_i = np.array([np.sum(RUi_j**2) for RUi_j in RU_i_j])\n",
    "    Sbar = np.mean(RU_r**2)\n",
    "    \n",
    "    Dsq = N/(N-1)*np.mean((RU_r**2-Sbar)**2)\n",
    "    T = np.sum((S_i-n_i*Sbar)**2/n_i)/Dsq\n",
    "    \n",
    "    p = stats.chi2(df=k-1).sf(T)\n",
    "    \n",
    "    return T, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1404eccf-1e36-4f1b-9df0-32c16c3dca65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.436484543493889, 0.024276602034339175)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i_j = [\n",
    "    np.array([ 14.97,   5.80,  25.03,   5.50 ]),\n",
    "    np.array([  5.83,  13.96,  21.96]),\n",
    "    np.array([ 17.89,  23.03,  61.09,   18.62,  55.51])\n",
    "]\n",
    "conover_squared_ranks_k_sample(x_i_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fed74796-d2cd-407c-8b21-89c7d64e16e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.3133164235890935, 0.1282701146119386)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i = np.array([8.56, 5.03, 48.1, 1.31, 4.82]); y_j = np.array([15.0, 12.3, 28.0, 13.9])\n",
    "x_i_j = [x_i, y_j]\n",
    "conover_squared_ranks_k_sample(x_i_j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c275738-9746-415b-b2e2-73fce0d853a3",
   "metadata": {},
   "source": [
    "## Pearson’s $r$\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fcb31e2b-8e64-4d02-a638-197e58fc0e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pearsons_r(x_i, y_i):\n",
    "    xbar = np.mean(x_i)\n",
    "    ybar = np.mean(y_i)\n",
    "    \n",
    "    return np.sum((x_i-xbar)*(y_i-ybar))/np.sqrt(np.sum((x_i-xbar)**2)*np.sum((y_i-ybar)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d26c5875-399b-44f9-854d-3a578206053e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5901002196595794"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i = np.array([9.64, 5.91, 3.22, 2.04, 5.49, 9.24, 6.38, 7.79, 0.48, 8.86])\n",
    "y_i = np.array([5.53, 3.48, 3.16, 2.98, 7.11, 7.75, 3.37, 8.24, 3.00, 3.75])\n",
    "\n",
    "get_pearsons_r(x_i, y_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994ca101-2c37-4288-bca9-4448c09e8fef",
   "metadata": {},
   "source": [
    "## Spearman’s $\\rho$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "291062e0-c803-455c-ba30-d34143a47649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spearmans_rho(x_i, y_i):\n",
    "    Rx_i = stats.rankdata(x_i)\n",
    "    Ry_i = stats.rankdata(y_i)\n",
    "    \n",
    "    Rbar = np.mean(Rx_i)\n",
    "    \n",
    "    rho = np.sum((Rx_i-Rbar)*(Ry_i-Rbar) / np.sqrt(np.sum((Rx_i-Rbar)**2)*np.sum((Ry_i-Rbar)**2)))\n",
    "    \n",
    "    return rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e37d0a2c-5969-44e7-9f74-837c6b9788b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7333333333333334"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_spearmans_rho(x_i, y_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8f2184-eccd-429d-92a6-61a105bc5b99",
   "metadata": {},
   "source": [
    "## Kendall’s $\\tau$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "693eb0d2-f8bc-42e7-b02c-1295868d930d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kendall_tau(x_i, y_i):\n",
    "    def is_concordant(pt1,pt2):\n",
    "        return ((pt1[0]>pt2[0])&(pt1[1]>pt2[1])|(pt1[0]<pt2[0])&(pt1[1]<pt2[1]))\n",
    "    def is_discordant(pt1,pt2):\n",
    "        return ((pt1[0]>pt2[0])&(pt1[1]<pt2[1])|(pt1[0]<pt2[0])&(pt1[1]>pt2[1]))\n",
    "    \n",
    "    assert len(x_i) == len(y_i)\n",
    "    n = len(x_i)\n",
    "    \n",
    "    Nc = np.sum([is_concordant((x_i[i],y_i[i]),(x_i[j],y_i[j])) for (i,j) in itertools.combinations(range(n),2)])\n",
    "    Nd = np.sum([is_discordant((x_i[i],y_i[i]),(x_i[j],y_i[j])) for (i,j) in itertools.combinations(range(n),2)])\n",
    "    \n",
    "    tau = (Nc-Nd)/(Nc+Nd); tau\n",
    "    \n",
    "    return tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "26598a9e-24ae-4be5-9028-3d085f1e34ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5555555555555556"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_kendall_tau(x_i, y_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7209a8-f6c4-431f-bc40-f9ae40cfbe89",
   "metadata": {},
   "source": [
    "## Friedman \n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3025c74b-033c-4f2b-bbf6-d61f59f61036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_friedman(X_ij):\n",
    "    b, k = np.shape(X_ij)\n",
    "    \n",
    "    R_ij = stats.rankdata(X_ij,axis=-1)\n",
    "    R_j = np.sum(R_ij,axis=0)\n",
    "    \n",
    "    T1 = (12/(b*k*(k+1)))*np.sum((R_j-0.5*b*(k+1))**2)\n",
    "    p = stats.chi2(df=k-1).sf(T1)\n",
    "    \n",
    "    return T1, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f1a2902f-8ee3-4bd1-b606-77d8a0291146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, 0.7788007830714049)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ij = np.array([[  2.  ,  50.0,   9.17],\n",
    "                 [  100005,   3.1 ,   3.34],\n",
    "                 [  0.14,  25.4 ,  26.59],\n",
    "                 [ 14.6 ,   -700,  10.95]])\n",
    "get_friedman(X_ij)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c309c9-28e1-48e0-bc89-14796acff208",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
