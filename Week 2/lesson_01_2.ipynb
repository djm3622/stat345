{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a94d06a3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# STAT 345: Nonparametric Statistics\n",
    "\n",
    "## Lesson 01.2: Random Samples, Inference and Confidence Intervals\n",
    "\n",
    "**Reading: Conover Sections 2.1-2.2**\n",
    "\n",
    "*Prof. John T. Whelan*\n",
    "\n",
    "Tuesday 21 January 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bc3202",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "These lecture slides are in a computational notebook.  You have access to them through http://vmware.rit.edu/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4619cd47",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Flat HTML and slideshow versions are also in MyCourses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2f190e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The notebook can run Python commands (other notebooks can use R or Julia; \"Ju-Pyt-R\").  Think: computational data analysis, not \"coding\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b751040a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Standard commands to activate inline interface and import libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d439f7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9858f27e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (8.0,5.0)\n",
    "plt.rcParams['font.size'] = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed3d000",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1 Random Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0e12b9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A typical scenario in statistical inference involves a data set\n",
    "$x_1,x_2,\\ldots,x_n\\equiv \\{x_i\\}\\equiv{{\\mathbf{x}}}$ which is assumed\n",
    "to be a realization of $n$ independent random variables\n",
    "${\\color{royalblue}{X_1}},{\\color{royalblue}{X_2}},\\ldots,{\\color{royalblue}{X_n}}\\equiv \\{{\\color{royalblue}{X_i}}\\}\\equiv{{\\mathbf{{\\color{royalblue}{X}}}}}$\n",
    "all drawn from some distribution $f(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a24cdb6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "(There are of course more complicated scenarios, like two random\n",
    "    samples $\\{{\\color{royalblue}{X_i}}\\}$ and $\\{{\\color{royalblue}{Y_j}}\\}$ from\n",
    "    different distributions, but we’ll consider the simple case first\n",
    "    for convenience.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4e5c30",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In the formalism of probability\n",
    "theory, there is a joint distribution function\n",
    "$$f(x_1,x_2,\\ldots,x_n) = f(x_1)f(x_2)\\cdots f(x_n)\n",
    "  \\ .$$ the typical goal of statistical inference is to say something\n",
    "about the distribution function $f(x)$ based on the observed data\n",
    "$\\{x_i\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b36dfb6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "(When talking about the distribution $f(x)$, it’s conventional to\n",
    "    talk about a random variable ${\\color{royalblue}{X}}$ with that\n",
    "    distribution. Of course ${\\color{royalblue}{X_1}}$,\n",
    "    ${\\color{royalblue}{X_2}}$, etc all have this distribution, so statements\n",
    "    about e.g., ${E\\left[{\\color{royalblue}{X}}\\right]}$ apply equally well\n",
    "    to ${E\\left[{\\color{royalblue}{X_1}}\\right]}$,\n",
    "    ${E\\left[{\\color{royalblue}{X_2}}\\right]}$, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74acd18f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In conventional applications, inference usually means\n",
    "constraining the unknown values of parameters\n",
    "$\\theta_1,\\theta_2,\\ldots,\\theta_p\\equiv\\{\\theta_j\\}\\equiv{{\\boldsymbol{\\theta}}}$\n",
    "in the distribution $f(x;{{\\boldsymbol{\\theta}}})$, such as the mean\n",
    "$\\mu$ and/or standard deviation $\\sigma$ in a normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314bf579",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Of\n",
    "course, in non-parametric statistics, the information we’re interested\n",
    "in not typically parameter values but rather more general information\n",
    "about the sampling distribution $f(x)$, but it’s helpful to have a\n",
    "reminder about the standard procedures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f4b7f3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "If our uncertainty about the sampling distribution $f(x;\\theta)$ can be\n",
    "described by a parameter $\\theta$, the standard problem of parametric\n",
    "inference is to make a statement about the unknown value $\\theta$ given\n",
    "the actual observed data ${{\\mathbf{x}}}\\equiv\n",
    "x_1,x_2,\\ldots,x_n$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02083de5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The difficulty is that what we actually have a\n",
    "mathematical description for is the probability distribution of the\n",
    "random vector ${{\\mathbf{{\\color{royalblue}{X}}}}}$ given the value of\n",
    "$\\theta$: $f({{\\mathbf{x}}};\\theta)$. This tells us about the\n",
    "probabilities associated with collecting additional data sets of the\n",
    "same sort as ${{\\mathbf{x}}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877f2372",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Bayesian statistics gets around this by\n",
    "interpreting $f({{\\mathbf{x}}};\\theta)$ as a conditional probability\n",
    "distribution $f({{\\mathbf{x}}}|\\theta,I)$ (given a value of $\\theta$ and\n",
    "background information $I$, e.g., that the parameterized model is the\n",
    "correct description in the first place) and using Bayes’s Theorem to\n",
    "construct\n",
    "$$f(\\theta|{{\\mathbf{x}}},I) = \\frac{f({{\\mathbf{x}}}|\\theta,I)\\,f(\\theta|I)}{f({{\\mathbf{x}}}|I)}$$\n",
    "which is a **posterior probability distribution** describing our\n",
    "knowledge of the parameter $\\theta$ after we’ve collected the data\n",
    "${{\\mathbf{x}}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9245a7a2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Classical frequentist methods instead construct a statistic\n",
    "$T({{\\mathbf{x}}})$ from the data, and describe the probability\n",
    "distribution of the random variable $T({{\\mathbf{{\\color{royalblue}{X}}}}})$\n",
    "for possible values of $\\theta$. Roughly speaking, reasonable values of\n",
    "$\\theta$ are those for which the value $T({{\\mathbf{x}}})$ is a\n",
    "“typical” value according to the behavior of the statistic\n",
    "$T({{\\mathbf{{\\color{royalblue}{X}}}}})$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7eb4c1b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2 Simulated Samples and Monte Carlo Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bb0036",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "There are a lot of theoretical and analytical methods to derive the properties of a statistic $T({{\\mathbf{{\\color{royalblue}{X}}}}})$ from those of the underlying distribution $f({{\\mathbf{x}}}|\\theta,I)$.  However, it is often useful to examine these properties using **Monte Carlo** simulations.  This could be as a cross-check on the derived properties, or because the situation is complicated enough that the derivation is difficult or impossible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad7034e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The `scipy.stats` module includes routines to generate random numbers according to known distributions.  For instance, to get a sample of 5 numbers from a standard normal distribution, you'd do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7048a1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "z_i = stats.norm.rvs(size=5); z_i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f76459",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "and if you call it again you'll get a different set of numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d849a8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "z_i = stats.norm.rvs(size=5); z_i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af48c0f2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Technically **pseudorandom** numbers, generated according to unpredictable mathematical procedures.  Can **seed** the random number generator, to choose reproducible starting point for pseudorandom sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1d9e7e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(8675309)\n",
    "z_i = stats.norm.rvs(size=5); z_i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27f13c0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If you give it the same starting seed again, you'll get the same set of numbers as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8639360f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(8675309)\n",
    "z_i = stats.norm.rvs(size=5); z_i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57117d37",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Ordinarily, seed the RNG once, at the start of your calculations.  The advantage of setting a seed is that if you re-run a program, or run it on a different machine, or someone else runs it, you'll get the same reproducible set of numbers.  For instance, I know that the sample in the cell above this one is\n",
    "\n",
    "    array([ 0.58902366,  0.73311856, -1.1621888 , -0.55681601, -0.77248843])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b16fd60",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "If you don't seed the pseudorandom number generator, or seed it with no argument, Python will use some truly random data taken from your clock, system temperature, etc to do the seeding, and the results will be unpredictable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf7007f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed()\n",
    "z_i = stats.norm.rvs(size=5); z_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbfc708",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed()\n",
    "z_i = stats.norm.rvs(size=5); z_i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd563bf0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's seed the random number generator once for the rest of this lesson:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886b1c27",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(135013)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbf0ec2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For a Monte Carlo simulation, rather than generate one sample $\\mathbf{x}\\equiv\\{x_i|i=1,\\ldots,n\\}$, we generate a large number $N$ of samples $\\{\\mathbf{x}^{(I)}|I=1,\\ldots,N\\}\\equiv\\{x^{(I)}_i|I=1,\\ldots,N;i=1,\\ldots,n\\}$.  Then if we have some statistic ${\\color{royalblue}{T}}=T({{\\mathbf{{\\color{royalblue}{X}}}}})$, we can generate some Monte Carlo ensemble $\\{T^{(I)}=T(\\mathbf{x}^{(I)})\\}$ representing that random variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ffbbe7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Nmonte = 10**3\n",
    "n = 100\n",
    "mu = 5\n",
    "sigma = 2\n",
    "x_Ii = stats.norm(loc=mu,scale=sigma).rvs(size=(Nmonte,n))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055422df",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "By specifying the tuple (Python's data type for a list which can't be changed) `(Nmonte,n)` for the sample size, we get back a $N\\times n$ array which we can think of as labelled by indices $I=1,\\ldots,N$ and $i=1,\\ldots,n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bc366f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x_Ii.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e1a669",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We've chosen a sample from a normal distribution with mean $\\mu=5$ and standard deviation $\\sigma=2$.  A standard result\n",
    "from intro statistics says that, given any distribution with mean\n",
    "$\\mu={E\\left[{\\color{royalblue}{X}}\\right]}$ and variance\n",
    "$\\operatorname{Var}({\\color{royalblue}{X}})\\equiv\n",
    "{E\\left[({\\color{royalblue}{X}}-\\mu)^2\\right]}=\\sigma^2$, if we construct the sample mean\n",
    "$${\\color{royalblue}{{{\\overline{X}}}}} = \\frac{{\\color{royalblue}{X}}_1+\\cdots+{\\color{royalblue}{X}}_n}{n}\n",
    "  =\\frac{1}{n}\\sum_{i=1}^n{\\color{royalblue}{X_i}}$$\n",
    "it will have properties\n",
    "$${E\\left[{\\color{royalblue}{{{\\overline{X}}}}}\\right]} = \\mu \\qquad\\hbox{and}\\qquad \\operatorname{Var}({\\color{royalblue}{{{\\overline{X}}}}})\n",
    "  =\\frac{\\sigma^2}{n}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8597699e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can test this using our Monte Carlo ensemble, which is the set of all the $\\{\\overline{x}^{(I)}\\}$ values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972d57c7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "xbar_I = np.mean(x_Ii,axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f633822b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Here the `axis=-1` means to take the average over the last index, i.e., convert the $N\\times n$ array into an $N$ element vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938771b0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "xbar_I.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c537f82f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5efcdfab",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We use the average of all the $\\{\\overline{x}^{(I)}\\}$ values as an estimate of the expectation value ${E\\left[{\\color{royalblue}{{{\\overline{X}}}}}\\right]}$ and their variance as an estimate of the variance $\\operatorname{Var}({\\color{royalblue}{{{\\overline{X}}}}})$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb1195e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print('E(Xbar)=%g; mu=%g' % (np.mean(xbar_I),mu))\n",
    "print('Var(Xbar)=%g; sigma^2/n=%g' % (np.var(xbar_I,ddof=1),sigma**2/n))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bcd1b4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The `ddof=1` just means that we construct the ensemble variance with $N-1$ rather than $N$ in the denominator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414c2a84",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Statistical theory also tells us that ${\\color{royalblue}{{{\\overline{X}}}}}$ will be a normally-distributed $N(\\mu,\\sigma^2/n)$ random variable.  We can check this by making a histogram of the $\\{\\overline{x}^{(I)}\\}$ values and comparing it to the expected normal distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d98653",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(xbar_I,bins=int(np.sqrt(Nmonte)),density=True,fc='white',ec='b');\n",
    "x_x = mu + np.linspace(-3.5,3.5,100) *(sigma/np.sqrt(n))\n",
    "plt.plot(x_x,stats.norm(loc=mu,scale=sigma/np.sqrt(n)).pdf(x_x));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0020886e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3 Confidence Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670707ab",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can use the sample mean\n",
    "${\\color{royalblue}{{{\\overline{X}}}}} = \\frac{1}{n}\\sum_{i=1}^n{\\color{royalblue}{X_i}}$ and sample variance\n",
    "$${\\color{royalblue}{S^2}} = \\frac{1}{n-1}\\sum_{i=1}^n\\left({\\color{royalblue}{X_i}}-{\\color{royalblue}{{{\\overline{X}}}}}\\right)^2$$\n",
    "as the basis for standard statistical inferences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3418011",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In addition to ${E\\left[{\\color{royalblue}{{{\\overline{X}}}}}\\right]} = \\mu$ and $\\operatorname{Var}({\\color{royalblue}{{{\\overline{X}}}}})\n",
    "  =\\frac{\\sigma^2}{n}$ mentioned above, we also have\n",
    "${E\\left[{\\color{royalblue}{S^2}}\\right]} = \\sigma^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fe85e4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note that\n",
    "${\\color{royalblue}{{{\\overline{X}}}}}$ is known as an **unbiased estimator**\n",
    "of $\\mu$ because ${E\\left[{\\color{royalblue}{{{\\overline{X}}}}}\\right]}=\\mu$,\n",
    "and likewise for ${\\color{royalblue}{S^2}}$ with $\\sigma^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cead479a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can use the sample mean ${\\color{royalblue}{{{\\overline{X}}}}}$ and variance ${\\color{royalblue}{S^2}}$\n",
    "to construct statistics\n",
    "$${\\color{royalblue}{Z}} = \\frac{{\\color{royalblue}{{{\\overline{X}}}}}-\\mu}{\\sqrt{\\sigma^2/n}}$$\n",
    "and\n",
    "$${\\color{royalblue}{T}} = \\frac{{\\color{royalblue}{{{\\overline{X}}}}}-\\mu}{\\sqrt{{\\color{royalblue}{S^2}}/n}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fa593d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Some important results from introductory statistics:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb1f699",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1.  When the underlying distribution $f(x;\\mu,\\sigma)$ is a\n",
    "    Gaussian (normal) $N(\\mu.\\sigma^2)$ with the appropriate parameters,\n",
    "    then ${\\color{royalblue}{Z}}$ is a standard normal random variable\n",
    "    $N(0,1)$, and ${\\color{royalblue}{T}}$ is Student-$t$ distributed with\n",
    "    $n-1$ degrees of freedom. (Student’s Theorem.)\n",
    "\n",
    "2.  When the sample size is large enough ($n\\gtrsim 30$\n",
    "    for ${\\color{royalblue}{Z}}$ and $n\\gtrsim 40$ for ${\\color{royalblue}{T}}$), for any underlying\n",
    "    distribution, both ${\\color{royalblue}{Z}}$ and ${\\color{royalblue}{T}}$ are\n",
    "    approximately normally distributed. (**Central Limit Theorem**.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a94954",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "(It's often worth using the $t$ distribution for ${\\color{royalblue}{T}}$ even when $n$ is large)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4561a63",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This can be used to construct a *confidence interval* for the parameter\n",
    "$\\mu$. For example, if $n$ is large, the statistic ${\\color{royalblue}{Z}}$\n",
    "will have a 5% chance of exceeding the 95th percentile of the standard\n",
    "normal distribution $z_{.95}\\approx 1.645$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0e69c2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "stats.norm.ppf(.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fd227b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note that this convention (Conover's) is the opposite of the notational convention in e.g., Devore, where $z_{\\alpha}$ is the $(1-\\alpha)\\times 100$th percentile rather than the $\\alpha\\times 100$th."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4322d9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "stats.norm.isf(.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508b93f6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This means that\n",
    "$$.05 \\approx\n",
    "P\\left({\\color{royalblue}{Z}}{\\mathbin{>}}z_{.95}\\right)\n",
    "=P\\left(\\frac{{\\color{royalblue}{{{\\overline{X}}}}}-\\mu}{\\sigma/\\sqrt{n}}{\\mathbin{>}}z_{.95}\\right)\n",
    "  =P\\left(\\mu{\\mathbin{<}}{\\color{royalblue}{{{\\overline{X}}}}} - z_{.95} \\sigma\\left/\\sqrt{n}\\right.\\right)$$\n",
    "If ${\\color{royalblue}{Z}}$, and thus ${\\color{royalblue}{{{\\overline{X}}}}}$, is unusually high, the unknown $\\mu$ will be a lot lower than the estimate ${\\color{royalblue}{{{\\overline{X}}}}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d66006b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Likewise, ${\\color{royalblue}{Z}}$ has a 5% chance of being less than the 5th percentile\n",
    "$z_{.05}\\approx -1.645$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463e16d8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "stats.norm.ppf(.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d404b56",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note $z_{.05}=-z_{.95}$ because the\n",
    "standard normal pdf is symmetric about the origin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890a2e1b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "stats.norm.ppf(.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351d2ae1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "So we have\n",
    "$$.05 \\approx\n",
    "  P\\left(\\frac{{\\color{royalblue}{{{\\overline{X}}}}}-\\mu}{\\sigma\\left/\\sqrt{n}\\right.}{\\mathbin{<}}z_{.05}\\right)\n",
    "  =P\\left({\\color{royalblue}{{{\\overline{X}}}}} - z_{.05} \\sigma\\left/\\sqrt{n}\\right.{\\mathbin{<}}\\mu\\right)\n",
    "  =P\\left({\\color{royalblue}{{{\\overline{X}}}}} + z_{.95} \\sigma\\left/\\sqrt{n}\\right.{\\mathbin{<}}\\mu\\right)\n",
    "  $$\n",
    "If ${\\color{royalblue}{Z}}$, and thus ${\\color{royalblue}{{{\\overline{X}}}}}$, is unusually low, the unknown $\\mu$ will be a lot higher than the estimate ${\\color{royalblue}{{{\\overline{X}}}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0f21c6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "There is a 90% chance that ${\\color{royalblue}{Z}}$ is neither below the 5th nor above the 95th percentile, in which case the interval bounded by\n",
    "${\\color{royalblue}{{{\\overline{X}}}}} \\pm z_{.95}\\,\\sigma\\left/\\sqrt{n}\\right.$\n",
    "will contain the true mean value $\\mu$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780fc8d0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We call this a 90% confidence\n",
    "interval. Note that the random quantity associated with the probability\n",
    "is not the unknown value of $\\mu$ (which is treated as fixed but unknown\n",
    "in the classical frequentist formalism), but rather the endpoints of the\n",
    "confidence interval constructed from random data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940d582f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Given an actual data\n",
    "set $\\{x_i\\}$, we construct the confidence interval as\n",
    "${{\\overline{x}}}\\pm z_{.95}\\,\\sigma\\left/\\sqrt{n}\\right.$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de83e64",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To illustrate the confidence interval, consider a sample of size $n=10$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce378a82",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(201908291)\n",
    "n = 10\n",
    "mu =  5\n",
    "sigma = 2\n",
    "x_i = stats.norm(loc=mu,scale=sigma).rvs(size=n); x_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76ccf1e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "x_i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887462e6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Suppose we know the underlying population has $\\sigma=2$.  We can construct a $90\\%$ confidence interval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e9dcd5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "alpha = 0.10; zcrit = stats.norm.ppf(1.-0.5*alpha)\n",
    "print('z_%.2f = %g' % (1.-0.5*alpha,zcrit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a735e879",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "xbar = np.mean(x_i); halfwidth = zcrit * sigma/np.sqrt(n) \n",
    "print ('%.0f%% CI is %g +/- %g i.e., (%g,%g)'\n",
    "       % (100*(1.-alpha),xbar,halfwidth,xbar-halfwidth,xbar+halfwidth))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d484591d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "As it happens the confidence interval does contain the true (unknown to the observer) value $\\mu=5$.\n",
    "There was a $90\\%$ chance of this happening given how the data were generated.  We can test this with a Monte Carlo by generating $N=1000$ samples, each with its own confidence interval, and seeing how many of them contain the true value..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9ca1c4",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "Nmonte = 1000\n",
    "x_Ii = stats.norm(loc=mu,scale=sigma).rvs(size=(Nmonte,n))\n",
    "xbar_I = np.mean(x_Ii,axis=-1)\n",
    "CIlo_I = xbar_I - halfwidth\n",
    "CIhi_I = xbar_I + halfwidth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87126639",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`CIlo_I` is an array of the lower bounds of $N$ confidence intervals, and `CIhi_I` is an array of the corresponding upper bounds.  To count how many contain the true value $\\mu$, construct a *Boolean array* which contains `True` for each confidence interval containing $\\mu$ and `False` for each which doesn't:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62aab914",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "inCI_I = (CIlo_I<mu) & (mu<CIhi_I)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4514c890",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Rather than look at all 1000 elements, let's just see the first 20:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be7dd3c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "inCI_I[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75866fbe",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "If we try to do math on the boolean variables, `True` is converted to $1$ and `False` to $0$, so we can take the sum to count how many are true:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5646743b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sum(inCI_I)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f96692",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "And to get the fraction that contain it, use the mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c23993",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "np.mean(inCI_I)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21ab501",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Of course, this is not exactly 90\\% because things are random."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c552ecb",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A question for you to consider (and answer on the homework): if you have 1000 confidence intervals, each of which is supposed to have a 90\\% chance of containing the true $\\mu$, how far from the expected number of 900 is it reasonable for the actual number containing $\\mu$ to be?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4721ca",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "If the population standard deviation $\\sigma$ is not known, the confidence interval has to be constructed from the statistic ${\\color{royalblue}{T}}$ instead, and this follows a Student-$t$ distribution with $n-1$ degrees of freedom, whose 95th percentile is $t_{n-1,0.95}$.  The confidence interval construction is\n",
    "\\begin{align*}\n",
    "0.90\n",
    "&=P\\left(\n",
    "{\\color{royalblue}{{{\\overline{X}}}}} - t_{n-1,0.95} \\sqrt{{\\color{royalblue}{S^2}}/n}\n",
    "{\\mathbin{<}}\\mu{\\mathbin{<}}\n",
    "{\\color{royalblue}{{{\\overline{X}}}}} - t_{n-1,0.05} \\sqrt{{\\color{royalblue}{S^2}}/n}\n",
    "\\right)\\\\\n",
    "&=P\\left(\n",
    "{\\color{royalblue}{{{\\overline{X}}}}} - t_{n-1,0.95} \\sqrt{{\\color{royalblue}{S^2}}/n}\n",
    "{\\mathbin{<}}\\mu{\\mathbin{<}}\n",
    "{\\color{royalblue}{{{\\overline{X}}}}} + t_{n-1,0.95} \\sqrt{{\\color{royalblue}{S^2}}/n}\n",
    "\\right)\n",
    "\\end{align*}\n",
    "and the 90\\% confidence interval has endpoints ${{\\overline{x}}}\\pm t_{n-1,0.95}\\,s\\left/\\sqrt{n}\\right.$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2a959b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note that as $n$ gets large $t_{n-1,0.95}$ is becomes well approximated by $z_{0.95}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad2930d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print('z_{%.2f}=%g'%(.95,stats.norm.ppf(.95)))\n",
    "n=10; print('t_{%d-1,%.2f}=%g'%(n,.95,stats.t(df=n-1).ppf(.95)))\n",
    "n=50; print('t_{%d-1,%.2f}=%g'%(n,.95,stats.t(df=n-1).ppf(.95)))\n",
    "n=100; print('t_{%d-1,%.2f}=%g'%(n,.95,stats.t(df=n-1).ppf(.95)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a4712d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "One final thing to note is that the central limit theorem means that the\n",
    "confidence interval construction is correct (for a sufficiently large sample) even if the sampling\n",
    "distribution is not normal, as long as it has a finite mean $\\mu$ and\n",
    "variance $\\sigma$.  (You will demonstrate this on the homework.)  However, it may not be the narrowest confidence\n",
    "interval we could construct at that confidence level, if the underlying\n",
    "distribution is non-normal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d789e073",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.1 Additional Demonstrations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e730e970",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A more extensive demonstration of Monte Carlo testing of confidence intervals can be found at [https://ccrg.rit.edu/~whelan/courses/2019_1sp_MATH_252/data/notebook07.html](https://ccrg.rit.edu/~whelan/courses/2019_1sp_MATH_252/data/notebook07.html) (HTML) or [https://ccrg.rit.edu/~whelan/courses/2019_1sp_MATH_252/data/notebook07.ipynb](https://ccrg.rit.edu/~whelan/courses/2019_1sp_MATH_252/data/notebook07.ipynb) (Jupyter notebook).  Use the username `bayes` and password `normal` to access them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a676eb9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "I've also added these in the \"Bonus Notebooks\" section of mycourses as [notebook07.ipynb](notebook07.ipynb) and [notebook07.html](notebook07.html), and they should be available on the JupyterHub server in the `lesson_01_2` directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954ba82e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4. Empirical Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34091daa",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "One piece of standard descriptive statistics that can actually be\n",
    "considered as a form of nonparametric inference is the histogram, which\n",
    "can be thought of as an approximation to either the pdf $f(x)$ or the\n",
    "pmf $p(x)$, depending on the sort of random variable we’re dealing with.\n",
    "For example, consider the following data sample (which we simulate from a Gamma distribution):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795c8679",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(20190830)\n",
    "mydist = stats.gamma(3,scale=10)\n",
    "x_i = mydist.rvs(size=20); x_i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60514abc",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For a small set of data, we can construct the histogram by hand, but NumPy provides a function which does the work for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2490bf",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(x_i,color='w',edgecolor='k',bins=np.arange(0,90,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee6fddb",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We see that 3 of the values are between 0 and 10, 6 between 10 and 20, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e5c40a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "If we want to turn this into an estimate of the pdf, though, we should scale the histogram so that the area under it adds up to one, and NumPy can also do that automatically, and then compare the histogram to the actual pdf of the distribution from which the data were drawn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26da69e2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x_x = np.linspace(0.,90.,1000)\n",
    "plt.plot(x_x,mydist.pdf(x_x));\n",
    "plt.hist(x_i,color='w',edgecolor='k',density=True,bins=np.arange(0,90,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae553c98",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "However, when you make a histogram, you need to decide where to place your bins, i.e., how finely are you going to divide up the $x$ values?  We could use larger bins, and then the histogram would be coarser but less susceptible to bin-to-bin fluctuations: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6dc076",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(x_i,color='w',edgecolor='k',density=True,bins=np.arange(0,90,20));\n",
    "plt.plot(x_x,mydist.pdf(x_x));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ae8962",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A way around that is to estimate the cdf\n",
    "$F(x)=P({\\color{royalblue}{X}}\\le x)$ rather than the pdf or pmf. The\n",
    "empirical distribution function $\\hat{F}(x;\\{x_i\\})$ \\[which Conover\n",
    "calls $S(x)$\\] is just the fraction of observations $\\{x_i\\}$ that are\n",
    "less than or equal to $x$. This can be easily estimated by using NumPy’s\n",
    "Boolean array construction; `A<=B` is an array containing `True`\n",
    "wherever the inequalities is satisfied, and `False` wherever it’s not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19826f24",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "mymask_xi = x_i[None,:] <= x_x[:,None]; mymask_xi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e02b39",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "mymask_xi.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e8f953",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This is a $1000\\times20$ boolean aray, telling us whether $x_i\\le x$ for each of the thousand $x$ values we plot and each of the twenty $x_i$ values in the sample.  If we take the mean of this array over $i$ for each of the $x$ values, it gives the fraction of `True` values, which is the empirical distribution function evaluated at $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee1e469",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Phat_x = np.mean(mymask_xi,axis=-1)\n",
    "Phat_x.shape, Phat_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71361871",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(x_x,Phat_x,label=r'$\\hat{F}(x;\\{x_i\\})$');\n",
    "plt.plot(x_x,mydist.cdf(x_x),label=r'$F(x)$ for Gamma(3,10)');\n",
    "plt.legend(loc='lower right');\n",
    "plt.xlabel(r'$x$');\n",
    "plt.ylabel('cdf');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14a499f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A few notes:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7759df78",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  * We've plotted the cdf of the Gamma distribution for comparison.  If we didn't know that the data came from that distribution, we could use this comparion to check that.  We will come back to this in Conover Chapter Six, about the Kolmogorov-Smirnov and related tests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b48925f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  * We didn't actually need to use a thousand $x$ values, since the empirical distribution function only changes value when $x$ passes through one of the $\\{x_i\\}$, but it works and doesn't burn up too much computing time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1a5564",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  * Conover considers a more involved method of estimating the survival function $1-F(x)$ in cases where some of the data are missing, known as the Kaplan-Meier estimator, but we’ll skip over that as it’s a bit advanced for our purposes right now."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
