{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fb9d279",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# STAT 345: Nonparametric Statistics\n",
    "\n",
    "## Lesson 03.2: Confidence Intervals for Quantiles\n",
    "\n",
    "**Reading: Conover Section 3.2**\n",
    "\n",
    "*Prof. John T. Whelan*\n",
    "\n",
    "Tuesday 4 February 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abdde50",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "These lecture slides are in a computational notebook.  You have access to them through http://vmware.rit.edu/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6023a53c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Flat HTML and slideshow versions are also in MyCourses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3f2ddd",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The notebook can run Python commands (other notebooks can use R or Julia; \"Ju-Pyt-R\").  Think: computational data analysis, not \"coding\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6677f387",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Standard commands to activate inline interface and import libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "020317d9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "442a8843",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (8.0,5.0)\n",
    "plt.rcParams['font.size'] = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a97a682",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Recall, for some $p^*\\in[0,1]$, the $p^*$ quantile $x_{p^*}$ of a random variable $\\color{royalblue}{X}$ is defined by\n",
    "$$P({\\color{royalblue}{X}}{\\mathbin{<}}x_{p^*}) \\le p^* \\qquad\\hbox{and}\\qquad P({\\color{royalblue}{X}}{\\mathbin{>}}x_{p^*}) = 1-P({\\color{royalblue}{X}}{\\mathbin{\\le}}x_{p^*})\\le 1-p^*$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7b84a0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- If $\\color{royalblue}{X}$ is a continuous rv, $P({\\color{royalblue}{X}}{\\mathbin{\\le}}x_{p^*})=P({\\color{royalblue}{X}}{\\mathbin{<}}x_{p^*})$ & the defn simplifies to $P({\\color{royalblue}{X}}{\\mathbin{\\le}}x_{p^*})=p^*$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60657cc",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Today, we'll consider how to construct a confidence interval for a quantile $x_{p^*}$, given the data $\\{x_i\\}=x_1,\\ldots,x_n$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b8e32b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- First, consider point estimator for a quantile.  An obvious estimator for the population median $x_{0.5}$ is the sample median, e.g., if $n=11$, this would be the 6th highest value in the sample, which has 5 values below and 5 above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c317d8ba",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Sample median is an example of an **order statistic**.  The $k$th order statistic of a sample $\\{{\\color{royalblue}{X_i}}\\}$ is written ${\\color{royalblue}{X^{(k)}}}$, and it’s simply the $k$th value in the sorted list of the sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677b875d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- E.g., if $x_1=1.3$, $x_2=-2.1$, $x_3=3.4$, and $x_4=0.7$,<br>we have $x^{(1)}=-2.1$,\n",
    "$x^{(2)}=0.7$, $x^{(3)}=1.3$, and $x^{(4)}=3.4$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e4b6001",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.1,  0.7,  1.3,  3.4])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i = np.array([1.3,-2.1,3.4,0.7])\n",
    "np.sort(x_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcdf5a6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- For a random sample $\\{{\\color{royalblue}{X_i}}\\}$, each order statistic ${\\color{royalblue}{X^{(k)}}}$ is a random variable which depends on the whole sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c096cdac",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Endpoints of confidence interval on quantile $x_{p^*}$ are order statistics; define a $1-\\alpha$ CI by\n",
    "$$\n",
    "  P({\\color{royalblue}{X^{(r)}}} {\\mathbin{\\le}}x_{p^*} {\\mathbin{\\le}}{\\color{royalblue}{X^{(s)}}}) = 1-\\alpha$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d339cb91",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Choose the integers $r$ and $s$ by considering\n",
    "the inequalities ${\\color{royalblue}{X^{(r)}}} {\\mathbin{\\le}}x_{p^*}$ and\n",
    "$x_{p^*} {\\mathbin{\\le}}{\\color{royalblue}{X^{(s)}}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f508fa",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Assuming for\n",
    "simplicity that we’re dealing with a continuous distribution, so that\n",
    "$P({\\color{royalblue}{X}}{\\mathbin{\\le}}x_{p^*})=P({\\color{royalblue}{X}}{\\mathbin{<}}x_{p^*})=p^*$\n",
    "for each point in the sample, the statement\n",
    "${\\color{royalblue}{X^{(r)}}} \\le x_{p^*}$ means that at least $r$ of the\n",
    "values in the sample are below $x_{p^*}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf69812",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- OTOH,\n",
    "$x_{p^*} \\le {\\color{royalblue}{X^{(s)}}}$ means that fewer than $s$ of the\n",
    "points in the sample are below $x_{p^*}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd14238",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- So if ${\\color{royalblue}{Y}}\\sim\\operatorname{Bin}(n,p^*)$ is the #\n",
    "of points in the sample below $x_{p^*}$, we can write\n",
    "$$P(r {\\mathbin{\\le}}{\\color{royalblue}{Y}} {\\mathbin{<}}s) = \\sum_{i=r}^{s-1} \\binom{n}{i} (p^*)^i(1-p^*)^{n-i}\n",
    "  = 1-\\alpha$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4803c757",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$$\n",
    "P({\\color{royalblue}{X^{(r)}}} {\\mathbin{\\le}}x_{p^*} {\\mathbin{\\le}}{\\color{royalblue}{X^{(s)}}}) = 1-\\alpha\n",
    "\\ \\hbox{where}\\ P(r {\\mathbin{\\le}}{\\color{royalblue}{Y}} {\\mathbin{<}}s) = \\sum_{i=r}^{s-1} \\binom{n}{i} (p^*)^i(1-p^*)^{n-i}\n",
    "  = 1-\\alpha\n",
    "$$\n",
    "- Find the `r` and `s` which satisfy this and pick the corresponding order statistics as the ends of the confidence interval."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36a6bc8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- As usual, if $np^*$ and $n(1-p^*)$ are large enough, we can us the\n",
    "normal approximation, along with $E({\\color{royalblue}{Y}})=np^*$ and\n",
    "$\\operatorname{Var}({\\color{royalblue}{Y}})=np^*(1-p^*)$, and the continuity\n",
    "correction $$P(r {\\mathbin{\\le}}{\\color{royalblue}{Y}} {\\mathbin{<}}s)\n",
    "  = P\\left(r-\\frac{1}{2} {\\mathbin{\\le}}{\\color{royalblue}{Y}} {\\mathbin{\\le}}s-\\frac{1}{2}\\right)\n",
    "  = 1-\\alpha$$ to write\n",
    "$$\\begin{aligned}\n",
    "    r-\\frac{1}{2} &\\approx np^* - z_{1-\\alpha/2} \\sqrt{np^*(1-p^*)}\\\\\n",
    "    s-\\frac{1}{2} &\\approx np^* + z_{1-\\alpha/2} \\sqrt{np^*(1-p^*)}\\\\\n",
    "  \\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9167cdd0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "To illustrate, let's take a random sample, as in the last lesson:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9df480b5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_i=np.array([0.5103, 0.9597, 0.0861, 0.4118, 0.2941, 0.2506, 0.3237, 0.4470, 0.4915, 0.6421,\n",
    "              0.5123, 0.8789, 0.3373, 1.6668, 0.1830, 0.8486, 0.5105, 0.6678, 0.2892, 0.3326,\n",
    "              1.2161, 3.6242, 0.4207, 0.8942, 1.6524, 1.8217, 0.2444, 0.1984, 0.3115, 1.6670,\n",
    "              0.2557, 0.5141, 3.0989, 0.6351, 0.8932, 0.4223, 0.8816, 1.3748, 0.1684, 1.0407])\n",
    "n = len(x_i); n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e431f914",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To get the order statistics $\\{x^{(i)}\\}$, we just have to sort the array $\\{x_i\\}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b980f5df",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0861, 0.1684, 0.183 , 0.1984, 0.2444, 0.2506, 0.2557, 0.2892,\n",
       "       0.2941, 0.3115, 0.3237, 0.3326, 0.3373, 0.4118, 0.4207, 0.4223,\n",
       "       0.447 , 0.4915, 0.5103, 0.5105, 0.5123, 0.5141, 0.6351, 0.6421,\n",
       "       0.6678, 0.8486, 0.8789, 0.8816, 0.8932, 0.8942, 0.9597, 1.0407,\n",
       "       1.2161, 1.3748, 1.6524, 1.6668, 1.667 , 1.8217, 3.0989, 3.6242])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xordered_i = np.sort(x_i); xordered_i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd97b0ef",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now let's construct a 90% confidence interval on the 60th percentile $x_{0.6}$ of the distribution.  The indices for the order statistics are $r$ and $s$, where 90% of the area under the null distribution $\\operatorname{Bin}(n,0.6)$ lies between $r$ and $s-1$, inclusive, i.e.,  $P(r {\\mathbin{\\le}}{\\color{royalblue}{Y}} {\\mathbin{<}}s)=P(r {\\mathbin{\\le}}{\\color{royalblue}{Y}} {\\mathbin{\\le}}(s-1))=0.9$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fbc0d1b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 30)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pstar = 0.6; alpha = 1. - 0.90; mydist = stats.binom(n,pstar)\n",
    "r,sm1 = mydist.interval(1.-alpha); r = int(r); s = int(sm1) + 1\n",
    "r,s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab0fc48",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "So $r=19$ and $s=30$.  Remembering that Python indexes from 0 rather than 1, we can extract the order statistics $x^{(19)}$ and $x^{(30)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e95bae8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The (at least) 90% CI on x_0.6 is from x^(19)=0.5103 to x^(30)=0.8942.\n"
     ]
    }
   ],
   "source": [
    "print('The (at least) %d%% CI on x_%.1f is from x^(%d)=%g to x^(%d)=%g.' %\n",
    "     (100*(1-alpha),pstar,r,xordered_i[r-1],s,xordered_i[s-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1731cc1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can check the actual coverage of the confidence interval, by looking at the probability between $r$ and $s-1$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3748a665",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CI on x_0.6 from x^(19)=0.5103 to x^(30)=0.8942 has coverage 92.561%.\n"
     ]
    }
   ],
   "source": [
    "print('The CI on x_%.1f from x^(%d)=%g to x^(%d)=%g has coverage %g%%.'\n",
    "      % (pstar,r,xordered_i[r-1],s,xordered_i[s-1],100*(mydist.cdf(s-1) - mydist.cdf(r-1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3e38cd",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "It is actually 92.6%, but we can verify this is the smallest coverage above 90%.  If we tried to reduce $s$ to 29 or increase $r$ to 20, we'd dip below 90%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68613e8b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CI on x_0.6 from x^(19)=0.5103 to x^(29)=0.8932 has coverage 88.9883%.\n",
      "The CI on x_0.6 from x^(20)=0.5105 to x^(30)=0.8942 has coverage 89.0426%.\n"
     ]
    }
   ],
   "source": [
    "print('The CI on x_%.1f from x^(%d)=%g to x^(%d)=%g has coverage %g%%.'\n",
    "      % (pstar,r,xordered_i[r-1],s-1,xordered_i[s-2],100*(mydist.cdf(s-2) - mydist.cdf(r-1))))\n",
    "print('The CI on x_%.1f from x^(%d)=%g to x^(%d)=%g has coverage %g%%.'\n",
    "      % (pstar,r+1,xordered_i[r],s,xordered_i[s-1],100*(mydist.cdf(s-1) - mydist.cdf(r))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4598cc3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can also check what the normal approximation would give us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41fd24d8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24.0, 3.0983866769659336)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu = mydist.mean(); sigma = mydist.std(); mu,sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ce3ff41",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6448536269514729"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zcrit = stats.norm.isf(0.5*alpha); zcrit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "567bc5e0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19.403607436694465, 29.596392563305535)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rn = 0.5 + mu - zcrit * sigma; sn = 0.5 + mu + zcrit * sigma; rn,sn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292224f3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If we round $r$ down and $s$ up to get a conservative interval, we see that again we get $x^{(19)}$ to $x^{(30)}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b87e730f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 30, 19, 30)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(int(np.floor(rn)),int(np.ceil(sn)),r,s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f7749a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Quantile intervals require care to avoid off-by-one errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db29e76",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "One place where there's a check is for a CI on the median $x_{0.5}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0140294",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The (at least) 90% CI on x_0.5 with n=40 is from x^(15)=0.4207 to x^(26)=0.8486.\n",
      "The exact coverage is 91.931%.\n"
     ]
    }
   ],
   "source": [
    "pstar = 0.5; alpha = 1. - 0.90; mydist = stats.binom(n,pstar)\n",
    "r,sm1 = mydist.interval(1.-alpha); r = int(r); s = int(sm1) + 1\n",
    "print('The (at least) %d%% CI on x_%.1f with n=%d is from x^(%d)=%g to x^(%d)=%g.' %\n",
    "     (100*(1-alpha),pstar,n,r,xordered_i[r-1],s,xordered_i[s-1]))\n",
    "print('The exact coverage is %g%%.' % (100*(mydist.cdf(s-1) - mydist.cdf(r-1))));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f9a1cd",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This should be symmetric, and we see there are $15-1=14$ values below $x^{(15)}$ and $40-26=14$ values above $x^{(26)}$ so it is indeed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab82f02d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Question: Can we ever have $\\gamma$ so large that we prove $H_1$ is true?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1551b08",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "For a test with critical region $C$, the power is $\\gamma=P(\\color{royalblue}{\\mathbf{X}}\\in C|H_1)$.\n",
    "- The power is a property of the test, not of the observation.\n",
    "- Could get $\\gamma=1$ if the test *always* rejected $H_0$, but that wouldn't make us conclude $H_1$ is true."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34228ab",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What can we conclude about $H_1$ from observing $\\mathbf{x}\\in C$ or more generally from some data $D$?\n",
    "Bayes's theorem tells us\n",
    "$$\n",
    "P(H_1|D) = \\frac{P(H_1,D)}{P(D)} = \\frac{P(D|H_1)P(H_1)}{P(D)}\n",
    "$$\n",
    "but to use this, need to define $P(H_1)$ (prior prob) & $P(D)$ (overall prob of observing what we did)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39705c8f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Even if $P(D|H_1)=1$, that doesn't tell us about $P(H_1|D)$, which still depends upon $P(H_1)$ and $P(D)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0f1ebf",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "On the other hand, what if $P(D|H_1)=0$ (and but $P(D)>0$ so $D$ is not a set of measure zero)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12e1da4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\n",
    "\\hbox{Then}\\qquad\n",
    "P(H_1|D)=\\frac{P(D|H_1)P(H_1)}{P(D)}=0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4083441e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "I.e., a hypothesis which tells us the observed data are impossible is definitely false."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd4bb44",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Don't really need probability to conclude that, only logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42d2158-355c-4d56-a3cd-6b68604d4d3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
